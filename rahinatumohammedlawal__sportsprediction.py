# -*- coding: utf-8 -*-
"""RahinatuMohammedLawal._SportsPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dnv8x3isAayp5xmBGOSqewsTKT5ZIYYn

QUESTION 1. DATA PREPROCESSING
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer
from sklearn.impute import IterativeImputer

# Loading the data set
MalePlayers = pd.read_csv("/content/drive/MyDrive/AI/male_players (legacy).csv")
Players22 =  pd.read_csv("/content/drive/MyDrive/AI/players_22.csv")

# Droping all columns with nan values of 30%
Less_nan = []
more_nan = []
for i in MalePlayers.columns:
    if((MalePlayers[i].isnull().sum()) < (0.3 * (MalePlayers.shape[0]))):
        Less_nan.append(i)

    else:
        more_nan.append(i)



MalePlayers = MalePlayers[Less_nan]

columns_to_drop = [
    "ls", "st", "rs", "lw", "lf", "cf", "rf", "rw",
    "lam", "cam", "ram", "lm", "lcm", "cm", "rcm", "rm",
    "lwb", "ldm", "cdm", "rdm", "rwb", "lb", "lcb", "cb",
    "rcb", "rb", "gk"
]

MalePlayers = MalePlayers.drop(columns=columns_to_drop)

# Separating the data set into numeric and categorical
numeric_data = MalePlayers.select_dtypes(include = np.number)
categorical_data = MalePlayers.select_dtypes(include = ['object'])


#Simple imputing the numeric data set and encoding the categorical dataset
#Numeric
imp = IterativeImputer(max_iter=10, random_state=0)
numeric_data = pd.DataFrame(np.round(imp.fit_transform(numeric_data)), columns=numeric_data.copy().columns)


#Categorical
values = np.array(categorical_data)
label_encoder = LabelEncoder()
label_encoder

for column in categorical_data.columns:
    if categorical_data[column].dtype == 'object':

        categorical_data[column] = categorical_data[column].astype(str)

        categorical_data[column] = label_encoder.fit_transform(categorical_data[column])



# Joining the numeric and the categorical
New_male_players= pd.concat([numeric_data,categorical_data],axis=1)


# Simple inputing the data set
simple_imput = SimpleImputer()
replace_data = simple_imput.fit_transform(New_male_players)
replace_data

New_male_players = pd.DataFrame(replace_data, columns = New_male_players.columns)
New_male_players


# Displaying 50 rows of the data
New_male_players.head(50)

"""QUESTION 2.        FEATURE ENGINEERING"""

#Visualizing the data to see the relation among the dataset
import matplotlib.pyplot as plt
def plot_correlation(df, target_column, columns_to_plot):
    correlation_columns = df[columns_to_plot].corrwith(df[target_column])

    correlation_columns = correlation_columns.sort_values(ascending = False)

    plt.figure(figsize = (10,6))
    correlation_columns.plot(kind = 'bar', color = 'violet')
    plt.title(f'correlation with{target_column}')
    plt.xlabel('Features')
    plt.ylabel('Correlation with Overall')
    plt.xticks(rotation = 90)
    plt.tight_layout()
    plt.show()

# Correlating the data set, to get the 10 most important features
correlated_data = New_male_players.corr()

predictive_variable = correlated_data['overall']

filtered_columns = predictive_variable[predictive_variable.abs() > 0.5].nlargest(10).index.tolist()

New_male_players = New_male_players[filtered_columns]

plot_correlation(New_male_players, 'overall', New_male_players.drop('overall', axis = 1).columns.tolist())


# Separating the data to y(predictive)  and X(other than the response)
y = New_male_players['overall']
X = New_male_players.drop('overall', axis = 1)

# Sclaing the independent data set
scaler=StandardScaler()
X=scaler.fit_transform(X)

"""QUESTION3.  TRAINING MODELS"""

from sklearn.model_selection import cross_val_score,  train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV, KFold
import xgboost as xgb


Xtrain,Xtest,Ytrain,Ytest=train_test_split(X, y, test_size=0.2,random_state=42)

# Declaring the numder of fold
n_fold = 10
kfold = KFold(n_splits=n_fold, shuffle=True, random_state=42)

# Training with the Random Forest Model
randomForest = RandomForestRegressor(n_estimators=10, random_state=42)
randomForest.fit(Xtrain, Ytrain)

# Making predictions on the test set
predictions = randomForest.predict(Xtest)

# Calculating mean squared error on test set
mse = mean_squared_error(Ytest, predictions)
print("Mean Squared Error on Test Set:", mse)

# Performing cross validation
rforest_scores = cross_val_score(randomForest, Xtrain, Ytrain, cv=kfold, scoring='neg_mean_squared_error')
print("Cross-validated Mean Squared Error:", np.sqrt(np.mean(-rforest_scores)))


print(f"Prediction with RandomForest:  {predictions}")

# Training with the Gradient Boosting

from sklearn.metrics import mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor

gradientBoosting = GradientBoostingRegressor(n_estimators=150, random_state=42)

gradientBoosting.fit(Xtrain, Ytrain)

predictions = gradientBoosting.predict(Xtest)

print("Size of prediction: ", len(predictions))
print("Prediction with Gradient Boosting: \n", predictions)

# Calculate mean squared error on test set
mse = mean_squared_error(Ytest, predictions)
print("Mean Squared Error on Test Set:", mse)

# Perform cross-validation if needed
gb_scores = cross_val_score(gradientBoosting, Xtrain, Ytrain, cv=kfold, scoring='neg_mean_squared_error')
print("Cross-validated Root Mean Squared Error:", np.sqrt(np.mean(-gb_scores)))

!pip install xgboost

# Training with the Xgboosting
import xgboost as xgb

xgBoost = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=150, random_state=42)

xgBoost.fit(Xtrain, Ytrain)

predictions = xgBoost.predict(Xtest)

print("Size of prediction: ", len(predictions))



mse = mean_squared_error(Ytest, predictions)
print("Mean Squared Error on Test Set:", mse)


xgb_scores = cross_val_score(xgBoost, Xtrain, Ytrain, cv=kfold, scoring='neg_mean_squared_error')
print("Cross-validated Root Mean Squared Error:", np.sqrt(np.mean(-xgb_scores)))

print("Prediction with XGBoost: \n", predictions)



"""QUESTION4. EVALUATION"""

#  Hyperparameter Tuning for xgboosting:
param_grid_xgb = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.1, 0.2]
}

grid_search_xgboost = GridSearchCV(xgBoost, param_grid_xgb, cv=kfold, scoring='neg_mean_absolute_error')
grid_search_xgboost.fit(X, y)

predictions = grid_search_xgboost.predict(Xtest)

mserror = mean_squared_error(Ytest, predictions)
print("Mean Squared Error on Test Set:", mserror)


best_xgb_model = grid_search_xgboost.best_estimator_
print("Best XGBoost Parameters: {grid_search_xgboost.best_params_}")

print(f"The prediction after tunning for xgboost:  {predictions}")

from sklearn.ensemble import VotingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score, train_test_split, KFold
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import xgboost as xgb
import numpy as np



# Split data into training and test sets
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.2, random_state=42)

# Declaring the number of folds for cross-validation
n_fold = 10
kfold = KFold(n_splits=n_fold, shuffle=True, random_state=42)

# Define individual models
randomForest = RandomForestRegressor(n_estimators=10, random_state=42)
gradientBoosting = GradientBoostingRegressor(n_estimators=150, random_state=42)
xgBoost = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=150, random_state=42)

# Create a VotingRegressor with the three base models
ensemble_model = VotingRegressor([
    ('Random Forest', randomForest),
    ('Gradient Boosting', gradientBoosting),
    ('XGBoost', xgBoost)
])

# Training the ensemble model
ensemble_model.fit(Xtrain, Ytrain)

# Making predictions and evaluating the ensemble model
predictions = ensemble_model.predict(Xtest)
mse = mean_squared_error(Ytest, predictions)
print("Ensemble Model Mean Squared Error on Test Set:", mse)

# Perform cross-validation if needed
ensemble_scores = cross_val_score(ensemble_model, Xtrain, Ytrain, cv=kfold, scoring='neg_mean_squared_error')
print("Ensemble Model Cross-validated Root Mean Squared Error:", np.sqrt(np.mean(-ensemble_scores)))

#  Hyperparameter Tuning for Gradient boosting:
import joblib
from sklearn.model_selection import RandomizedSearchCV
param_ensemble= {
    'Random Forest__n_estimators': [50, 100, 200],
    'Random Forest__max_depth': [None, 10, 20],
    'Random Forest__min_samples_split': [2, 5, 10],
    'Random Forest__min_samples_leaf': [1, 2, 4],
    'XGBoost__n_estimators': [50, 100, 200],
    'XGBoost__max_depth': [3, 6, 9],
    'XGBoost__learning_rate': [0.01, 0.1, 0.2],
    'Gradient Boosting__n_estimators': [50, 100, 200],
    'Gradient Boosting__max_depth': [3, 6, 9],
    'Gradient Boosting__learning_rate': [0.01, 0.1, 0.2]
}


joblib_parallel_backend = joblib.parallel_backend('loky', n_jobs=-1)

with joblib_parallel_backend:
    # Performing RandomizedSearchCV for the ensemble model
    grid_search = RandomizedSearchCV(ensemble_model, param_ensemble, cv=5, scoring='neg_mean_absolute_error', verbose=2, n_jobs=-1)
    grid_search.fit(Xtrain, Ytrain)
predicted = grid_search.predict(Xtest)

mserror = mean_squared_error(Ytest, predicted)
print("Mean Squared Error on Test Set:", mserror)

best_gb_model = grid_search.best_estimator_
print(f"Best Gradient Boosting Parameters: {grid_search.best_params_}")

print(f"The prediction after tuning for gradient boosting is : {predicted}")



"""QUESTION 5.  TESTING WITH THE PLAYER22 DATA SET"""

def preprocess_data(df, columns_of_interest):
    # Select columns of interest
    df = df[columns_of_interest]

    # Separating the data into numeric and categorical
    numeric_data = df.select_dtypes(include=np.number)
    categorical_data = df.select_dtypes(include=['object'])

    # Imputing the numeric data
    imp = IterativeImputer(max_iter=10, random_state=0)
    numeric_data = pd.DataFrame(np.round(imp.fit_transform(numeric_data)), columns=numeric_data.columns)

    # Encode the categorical data
    label_encoder = LabelEncoder()
    for column in categorical_data.columns:
        if categorical_data[column].dtype == 'object':
            categorical_data[column] = categorical_data[column].astype(str)
            categorical_data[column] = label_encoder.fit_transform(categorical_data[column])

    # Join the numeric and categorical data
    df = pd.concat([numeric_data, categorical_data], axis=1)

    # Simple impute the entire data set
    simple_imput = SimpleImputer()
    replace_data = simple_imput.fit_transform(df)
    df = pd.DataFrame(replace_data, columns=df.columns)

    return df

# Example usage
columns_of_interest = ['overall', 'movement_reactions', 'mentality_composure', 'potential',
                       'wage_eur', 'value_eur', 'passing']

# Assume player22 is your DataFrame
Player22 = preprocess_data(Players22, columns_of_interest)


Player22.head()

# Separating into test
y_test = Player22['overall']
X_test = Player22.drop('overall', axis = 1)



# Evaluating the best model
from sklearn.metrics import mean_absolute_error, root_mean_s

# Evaluate  emblemed Model
rf_pred = grid_search.predict(X_test)
rf_mae = mean_absolute_error(y_test, rf_pred)
print(f"Random Forest Test MAE: {rf_mae}")
print(f"Random Forest Test RMSE: {np.sqrt(rf_mae)}")

import joblib

joblib.dump(xgBoost, "model.pkl")

import joblib

loaded_model = joblib.load("model.pkl")
loaded_scaler = joblib.load("scaler.pkl")